{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ipkXJ0vFGnIe",
        "outputId": "3ef1941a-22dd-452e-c1c3-fac34ae7ce61"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "NỒI CƠM ĐIỆN"
      ],
      "metadata": {
        "id": "_WLsHiM5INNw"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from googleapiclient.discovery import build\n",
        "import pandas as pd\n",
        "\n",
        "# ====== 1. Cấu hình API ======\n",
        "API_KEY = \"AIzaSyAuFRQHAvs2n3c6b2eS-SVw8UdfaB9YbxM\"\n",
        "YOUTUBE_API_SERVICE_NAME = \"youtube\"\n",
        "YOUTUBE_API_VERSION = \"v3\"\n",
        "\n",
        "youtube = build(YOUTUBE_API_SERVICE_NAME, YOUTUBE_API_VERSION, developerKey=API_KEY)\n",
        "\n",
        "# ====== 2. Hàm crawl video ======\n",
        "def youtube_search_scroll(query, max_videos=100):\n",
        "    videos = []\n",
        "    next_page_token = None\n",
        "\n",
        "    while len(videos) < max_videos:\n",
        "        search_response = youtube.search().list(\n",
        "            q=query,\n",
        "            part=\"id,snippet\",\n",
        "            type=\"video\",\n",
        "            maxResults=50,\n",
        "            pageToken=next_page_token\n",
        "        ).execute()\n",
        "\n",
        "        for item in search_response.get(\"items\", []):\n",
        "            video_id = item[\"id\"][\"videoId\"]\n",
        "\n",
        "            # Lấy chi tiết video\n",
        "            video_response = youtube.videos().list(\n",
        "                part=\"snippet,statistics\",\n",
        "                id=video_id\n",
        "            ).execute()\n",
        "\n",
        "            for video in video_response.get(\"items\", []):\n",
        "                snippet = video[\"snippet\"]\n",
        "                stats = video.get(\"statistics\", {})\n",
        "\n",
        "                videos.append({\n",
        "                    \"title\": snippet[\"title\"],\n",
        "                    \"views\": stats.get(\"viewCount\", 0),\n",
        "                    \"likes\": stats.get(\"likeCount\", 0),\n",
        "                    \"comments\": stats.get(\"commentCount\", 0),\n",
        "                    \"publishedAt\": snippet[\"publishedAt\"].split(\"T\")[0],  # chỉ lấy YYYY-MM-DD\n",
        "                    \"tags\": \", \".join(snippet.get(\"tags\", [])) if \"tags\" in snippet else \"\",\n",
        "                    \"channelTitle\": snippet.get(\"channelTitle\", \"\")\n",
        "                })\n",
        "\n",
        "        # Nếu có trang tiếp theo thì crawl tiếp\n",
        "        next_page_token = search_response.get(\"nextPageToken\")\n",
        "        if not next_page_token:\n",
        "            break  # hết dữ liệu\n",
        "\n",
        "    return videos[:max_videos]\n",
        "\n",
        "# ====== 3. Crawl dữ liệu ======\n",
        "query = \"nồi cơm điện\"\n",
        "results = youtube_search_scroll(query, max_videos=500)\n",
        "\n",
        "# ====== 4. Xuất CSV ======\n",
        "df = pd.DataFrame(results)\n",
        "df.to_csv(\"/content/drive/MyDrive/Youtube_crawled_data/NOICOMDIEN_videos.csv\", index=False, encoding=\"utf-8-sig\")\n",
        "\n",
        "print(\"✅ Đã lưu thành công vào noicomdien_videos.csv\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BbkMJ3OiGtiZ",
        "outputId": "63b6c89e-64bd-4511-9ffc-6236923845ad"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "✅ Đã lưu thành công vào noicomdien_videos.csv\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "TỦ LẠNH"
      ],
      "metadata": {
        "id": "lZolWVGQIQOy"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from googleapiclient.discovery import build\n",
        "import pandas as pd\n",
        "\n",
        "# ====== 1. Cấu hình API ======\n",
        "API_KEY = \"AIzaSyAuFRQHAvs2n3c6b2eS-SVw8UdfaB9YbxM\"\n",
        "YOUTUBE_API_SERVICE_NAME = \"youtube\"\n",
        "YOUTUBE_API_VERSION = \"v3\"\n",
        "\n",
        "youtube = build(YOUTUBE_API_SERVICE_NAME, YOUTUBE_API_VERSION, developerKey=API_KEY)\n",
        "\n",
        "# ====== 2. Hàm crawl video ======\n",
        "def youtube_search_scroll(query, max_videos=100):\n",
        "    videos = []\n",
        "    next_page_token = None\n",
        "\n",
        "    while len(videos) < max_videos:\n",
        "        search_response = youtube.search().list(\n",
        "            q=query,\n",
        "            part=\"id,snippet\",\n",
        "            type=\"video\",\n",
        "            maxResults=50,\n",
        "            pageToken=next_page_token\n",
        "        ).execute()\n",
        "\n",
        "        for item in search_response.get(\"items\", []):\n",
        "            video_id = item[\"id\"][\"videoId\"]\n",
        "\n",
        "            # Lấy chi tiết video\n",
        "            video_response = youtube.videos().list(\n",
        "                part=\"snippet,statistics\",\n",
        "                id=video_id\n",
        "            ).execute()\n",
        "\n",
        "            for video in video_response.get(\"items\", []):\n",
        "                snippet = video[\"snippet\"]\n",
        "                stats = video.get(\"statistics\", {})\n",
        "\n",
        "                videos.append({\n",
        "                    \"title\": snippet[\"title\"],\n",
        "                    \"views\": stats.get(\"viewCount\", 0),\n",
        "                    \"likes\": stats.get(\"likeCount\", 0),\n",
        "                    \"comments\": stats.get(\"commentCount\", 0),\n",
        "                    \"publishedAt\": snippet[\"publishedAt\"].split(\"T\")[0],  # chỉ lấy YYYY-MM-DD\n",
        "                    \"tags\": \", \".join(snippet.get(\"tags\", [])) if \"tags\" in snippet else \"\",\n",
        "                    \"channelTitle\": snippet.get(\"channelTitle\", \"\")\n",
        "                })\n",
        "\n",
        "        # Nếu có trang tiếp theo thì crawl tiếp\n",
        "        next_page_token = search_response.get(\"nextPageToken\")\n",
        "        if not next_page_token:\n",
        "            break  # hết dữ liệu\n",
        "\n",
        "    return videos[:max_videos]\n",
        "\n",
        "# ====== 3. Crawl dữ liệu ======\n",
        "query = \"tủ lạnh\"\n",
        "results = youtube_search_scroll(query, max_videos=500)\n",
        "\n",
        "# ====== 4. Xuất CSV ======\n",
        "df = pd.DataFrame(results)\n",
        "df.to_csv(\"/content/drive/MyDrive/Youtube_crawled_data/TULANH_videos.csv\", index=False, encoding=\"utf-8-sig\")\n",
        "\n",
        "print(\"✅ Đã lưu thành công vào TULANH_videos.csv\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Ts-B_p2IIRYn",
        "outputId": "adc9ec7a-f0cc-4878-ce37-5cd84ee8883e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "✅ Đã lưu thành công vào TULANH_videos.csv\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "MÁY GIẶT"
      ],
      "metadata": {
        "id": "7i99im1QJDOE"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from googleapiclient.discovery import build\n",
        "import pandas as pd\n",
        "\n",
        "# ====== 1. Cấu hình API ======\n",
        "API_KEY = \"AIzaSyAuFRQHAvs2n3c6b2eS-SVw8UdfaB9YbxM\"\n",
        "YOUTUBE_API_SERVICE_NAME = \"youtube\"\n",
        "YOUTUBE_API_VERSION = \"v3\"\n",
        "\n",
        "youtube = build(YOUTUBE_API_SERVICE_NAME, YOUTUBE_API_VERSION, developerKey=API_KEY)\n",
        "\n",
        "# ====== 2. Hàm crawl video ======\n",
        "def youtube_search_scroll(query, max_videos=100):\n",
        "    videos = []\n",
        "    next_page_token = None\n",
        "\n",
        "    while len(videos) < max_videos:\n",
        "        search_response = youtube.search().list(\n",
        "            q=query,\n",
        "            part=\"id,snippet\",\n",
        "            type=\"video\",\n",
        "            maxResults=50,\n",
        "            pageToken=next_page_token\n",
        "        ).execute()\n",
        "\n",
        "        for item in search_response.get(\"items\", []):\n",
        "            video_id = item[\"id\"][\"videoId\"]\n",
        "\n",
        "            # Lấy chi tiết video\n",
        "            video_response = youtube.videos().list(\n",
        "                part=\"snippet,statistics\",\n",
        "                id=video_id\n",
        "            ).execute()\n",
        "\n",
        "            for video in video_response.get(\"items\", []):\n",
        "                snippet = video[\"snippet\"]\n",
        "                stats = video.get(\"statistics\", {})\n",
        "\n",
        "                videos.append({\n",
        "                    \"title\": snippet[\"title\"],\n",
        "                    \"views\": stats.get(\"viewCount\", 0),\n",
        "                    \"likes\": stats.get(\"likeCount\", 0),\n",
        "                    \"comments\": stats.get(\"commentCount\", 0),\n",
        "                    \"publishedAt\": snippet[\"publishedAt\"].split(\"T\")[0],  # chỉ lấy YYYY-MM-DD\n",
        "                    \"tags\": \", \".join(snippet.get(\"tags\", [])) if \"tags\" in snippet else \"\",\n",
        "                    \"channelTitle\": snippet.get(\"channelTitle\", \"\")\n",
        "                })\n",
        "\n",
        "        # Nếu có trang tiếp theo thì crawl tiếp\n",
        "        next_page_token = search_response.get(\"nextPageToken\")\n",
        "        if not next_page_token:\n",
        "            break  # hết dữ liệu\n",
        "\n",
        "    return videos[:max_videos]\n",
        "\n",
        "# ====== 3. Crawl dữ liệu ======\n",
        "query = \"máy giặt\"\n",
        "results = youtube_search_scroll(query, max_videos=500)\n",
        "\n",
        "# ====== 4. Xuất CSV ======\n",
        "df = pd.DataFrame(results)\n",
        "df.to_csv(\"/content/drive/MyDrive/Youtube_crawled_data/MAYGIAT_videos.csv\", index=False, encoding=\"utf-8-sig\")\n",
        "\n",
        "print(\"✅ Đã lưu thành công vào MAYGIAT_videos.csv\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "aDl6_LQDJF68",
        "outputId": "71c3c6ea-ff58-4193-94fc-ea980664f8b0"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "✅ Đã lưu thành công vào MAYGIAT_videos.csv\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "QUẠT"
      ],
      "metadata": {
        "id": "zXDidnZRJNAv"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from googleapiclient.discovery import build\n",
        "import pandas as pd\n",
        "\n",
        "# ====== 1. Cấu hình API ======\n",
        "API_KEY = \"AIzaSyAuFRQHAvs2n3c6b2eS-SVw8UdfaB9YbxM\"\n",
        "YOUTUBE_API_SERVICE_NAME = \"youtube\"\n",
        "YOUTUBE_API_VERSION = \"v3\"\n",
        "\n",
        "youtube = build(YOUTUBE_API_SERVICE_NAME, YOUTUBE_API_VERSION, developerKey=API_KEY)\n",
        "\n",
        "# ====== 2. Hàm crawl video ======\n",
        "def youtube_search_scroll(query, max_videos=100):\n",
        "    videos = []\n",
        "    next_page_token = None\n",
        "\n",
        "    while len(videos) < max_videos:\n",
        "        search_response = youtube.search().list(\n",
        "            q=query,\n",
        "            part=\"id,snippet\",\n",
        "            type=\"video\",\n",
        "            maxResults=50,\n",
        "            pageToken=next_page_token\n",
        "        ).execute()\n",
        "\n",
        "        for item in search_response.get(\"items\", []):\n",
        "            video_id = item[\"id\"][\"videoId\"]\n",
        "\n",
        "            # Lấy chi tiết video\n",
        "            video_response = youtube.videos().list(\n",
        "                part=\"snippet,statistics\",\n",
        "                id=video_id\n",
        "            ).execute()\n",
        "\n",
        "            for video in video_response.get(\"items\", []):\n",
        "                snippet = video[\"snippet\"]\n",
        "                stats = video.get(\"statistics\", {})\n",
        "\n",
        "                videos.append({\n",
        "                    \"title\": snippet[\"title\"],\n",
        "                    \"views\": stats.get(\"viewCount\", 0),\n",
        "                    \"likes\": stats.get(\"likeCount\", 0),\n",
        "                    \"comments\": stats.get(\"commentCount\", 0),\n",
        "                    \"publishedAt\": snippet[\"publishedAt\"].split(\"T\")[0],  # chỉ lấy YYYY-MM-DD\n",
        "                    \"tags\": \", \".join(snippet.get(\"tags\", [])) if \"tags\" in snippet else \"\",\n",
        "                    \"channelTitle\": snippet.get(\"channelTitle\", \"\")\n",
        "                })\n",
        "\n",
        "        # Nếu có trang tiếp theo thì crawl tiếp\n",
        "        next_page_token = search_response.get(\"nextPageToken\")\n",
        "        if not next_page_token:\n",
        "            break  # hết dữ liệu\n",
        "\n",
        "    return videos[:max_videos]\n",
        "\n",
        "# ====== 3. Crawl dữ liệu ======\n",
        "query = \"quạt\"\n",
        "results = youtube_search_scroll(query, max_videos=500)\n",
        "\n",
        "# ====== 4. Xuất CSV ======\n",
        "df = pd.DataFrame(results)\n",
        "df.to_csv(\"/content/drive/MyDrive/Youtube_crawled_data/QUAT_videos.csv\", index=False, encoding=\"utf-8-sig\")\n",
        "\n",
        "print(\"✅ Đã lưu thành công vào QUAT_videos.csv\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "28a0TZhUJQWj",
        "outputId": "e406a091-cb4f-45d3-876e-c66e125c5b0c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "✅ Đã lưu thành công vào QUAT_videos.csv\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "ẤM SIÊU TỐC"
      ],
      "metadata": {
        "id": "EktvFMFTJX6M"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from googleapiclient.discovery import build\n",
        "import pandas as pd\n",
        "\n",
        "# ====== 1. Cấu hình API ======\n",
        "API_KEY = \"AIzaSyAuFRQHAvs2n3c6b2eS-SVw8UdfaB9YbxM\"\n",
        "YOUTUBE_API_SERVICE_NAME = \"youtube\"\n",
        "YOUTUBE_API_VERSION = \"v3\"\n",
        "\n",
        "youtube = build(YOUTUBE_API_SERVICE_NAME, YOUTUBE_API_VERSION, developerKey=API_KEY)\n",
        "\n",
        "# ====== 2. Hàm crawl video ======\n",
        "def youtube_search_scroll(query, max_videos=100):\n",
        "    videos = []\n",
        "    next_page_token = None\n",
        "\n",
        "    while len(videos) < max_videos:\n",
        "        search_response = youtube.search().list(\n",
        "            q=query,\n",
        "            part=\"id,snippet\",\n",
        "            type=\"video\",\n",
        "            maxResults=50,\n",
        "            pageToken=next_page_token\n",
        "        ).execute()\n",
        "\n",
        "        for item in search_response.get(\"items\", []):\n",
        "            video_id = item[\"id\"][\"videoId\"]\n",
        "\n",
        "            # Lấy chi tiết video\n",
        "            video_response = youtube.videos().list(\n",
        "                part=\"snippet,statistics\",\n",
        "                id=video_id\n",
        "            ).execute()\n",
        "\n",
        "            for video in video_response.get(\"items\", []):\n",
        "                snippet = video[\"snippet\"]\n",
        "                stats = video.get(\"statistics\", {})\n",
        "\n",
        "                videos.append({\n",
        "                    \"title\": snippet[\"title\"],\n",
        "                    \"views\": stats.get(\"viewCount\", 0),\n",
        "                    \"likes\": stats.get(\"likeCount\", 0),\n",
        "                    \"comments\": stats.get(\"commentCount\", 0),\n",
        "                    \"publishedAt\": snippet[\"publishedAt\"].split(\"T\")[0],  # chỉ lấy YYYY-MM-DD\n",
        "                    \"tags\": \", \".join(snippet.get(\"tags\", [])) if \"tags\" in snippet else \"\",\n",
        "                    \"channelTitle\": snippet.get(\"channelTitle\", \"\")\n",
        "                })\n",
        "\n",
        "        # Nếu có trang tiếp theo thì crawl tiếp\n",
        "        next_page_token = search_response.get(\"nextPageToken\")\n",
        "        if not next_page_token:\n",
        "            break  # hết dữ liệu\n",
        "\n",
        "    return videos[:max_videos]\n",
        "\n",
        "# ====== 3. Crawl dữ liệu ======\n",
        "query = \"ấm siêu tốc\"\n",
        "results = youtube_search_scroll(query, max_videos=500)\n",
        "\n",
        "# ====== 4. Xuất CSV ======\n",
        "df = pd.DataFrame(results)\n",
        "df.to_csv(\"/content/drive/MyDrive/Youtube_crawled_data/AMSIEUTOC_videos.csv\", index=False, encoding=\"utf-8-sig\")\n",
        "\n",
        "print(\"✅ Đã lưu thành công vào AMSIEUTOC_videos.csv\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PBhrSa3hJbra",
        "outputId": "26905da1-0b0b-456f-a6fa-253e6a7b2e51"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "✅ Đã lưu thành công vào AMSIEUTOC_videos.csv\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "MÁY HÚT BỤI"
      ],
      "metadata": {
        "id": "M73lfjV8JsFv"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from googleapiclient.discovery import build\n",
        "import pandas as pd\n",
        "\n",
        "# ====== 1. Cấu hình API ======\n",
        "API_KEY = \"AIzaSyAuFRQHAvs2n3c6b2eS-SVw8UdfaB9YbxM\"\n",
        "YOUTUBE_API_SERVICE_NAME = \"youtube\"\n",
        "YOUTUBE_API_VERSION = \"v3\"\n",
        "\n",
        "youtube = build(YOUTUBE_API_SERVICE_NAME, YOUTUBE_API_VERSION, developerKey=API_KEY)\n",
        "\n",
        "# ====== 2. Hàm crawl video ======\n",
        "def youtube_search_scroll(query, max_videos=100):\n",
        "    videos = []\n",
        "    next_page_token = None\n",
        "\n",
        "    while len(videos) < max_videos:\n",
        "        search_response = youtube.search().list(\n",
        "            q=query,\n",
        "            part=\"id,snippet\",\n",
        "            type=\"video\",\n",
        "            maxResults=50,\n",
        "            pageToken=next_page_token\n",
        "        ).execute()\n",
        "\n",
        "        for item in search_response.get(\"items\", []):\n",
        "            video_id = item[\"id\"][\"videoId\"]\n",
        "\n",
        "            # Lấy chi tiết video\n",
        "            video_response = youtube.videos().list(\n",
        "                part=\"snippet,statistics\",\n",
        "                id=video_id\n",
        "            ).execute()\n",
        "\n",
        "            for video in video_response.get(\"items\", []):\n",
        "                snippet = video[\"snippet\"]\n",
        "                stats = video.get(\"statistics\", {})\n",
        "\n",
        "                videos.append({\n",
        "                    \"title\": snippet[\"title\"],\n",
        "                    \"views\": stats.get(\"viewCount\", 0),\n",
        "                    \"likes\": stats.get(\"likeCount\", 0),\n",
        "                    \"comments\": stats.get(\"commentCount\", 0),\n",
        "                    \"publishedAt\": snippet[\"publishedAt\"].split(\"T\")[0],  # chỉ lấy YYYY-MM-DD\n",
        "                    \"tags\": \", \".join(snippet.get(\"tags\", [])) if \"tags\" in snippet else \"\",\n",
        "                    \"channelTitle\": snippet.get(\"channelTitle\", \"\")\n",
        "                })\n",
        "\n",
        "        # Nếu có trang tiếp theo thì crawl tiếp\n",
        "        next_page_token = search_response.get(\"nextPageToken\")\n",
        "        if not next_page_token:\n",
        "            break  # hết dữ liệu\n",
        "\n",
        "    return videos[:max_videos]\n",
        "\n",
        "# ====== 3. Crawl dữ liệu ======\n",
        "query = \"máy hút bụi\"\n",
        "results = youtube_search_scroll(query, max_videos=500)\n",
        "\n",
        "# ====== 4. Xuất CSV ======\n",
        "df = pd.DataFrame(results)\n",
        "df.to_csv(\"/content/drive/MyDrive/Youtube_crawled_data/MAYHUTBUI_videos.csv\", index=False, encoding=\"utf-8-sig\")\n",
        "\n",
        "print(\"✅ Đã lưu thành công vào MAYHUTBUI_videos.csv\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QnCehcYeJyu5",
        "outputId": "4c823780-a29e-4175-eadf-2e684b903bb8"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "✅ Đã lưu thành công vào MAYHUTBUI_videos.csv\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "TIVI"
      ],
      "metadata": {
        "id": "p5ETX07BJ8mX"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from googleapiclient.discovery import build\n",
        "import pandas as pd\n",
        "\n",
        "# ====== 1. Cấu hình API ======\n",
        "API_KEY = \"AIzaSyAS5BoEfqdEIMxRrXO1MfA8WHYrFwrSHhE\"\n",
        "YOUTUBE_API_SERVICE_NAME = \"youtube\"\n",
        "YOUTUBE_API_VERSION = \"v3\"\n",
        "\n",
        "youtube = build(YOUTUBE_API_SERVICE_NAME, YOUTUBE_API_VERSION, developerKey=API_KEY)\n",
        "\n",
        "# ====== 2. Hàm crawl video ======\n",
        "def youtube_search_scroll(query, max_videos=100):\n",
        "    videos = []\n",
        "    next_page_token = None\n",
        "\n",
        "    while len(videos) < max_videos:\n",
        "        search_response = youtube.search().list(\n",
        "            q=query,\n",
        "            part=\"id,snippet\",\n",
        "            type=\"video\",\n",
        "            maxResults=50,\n",
        "            pageToken=next_page_token\n",
        "        ).execute()\n",
        "\n",
        "        for item in search_response.get(\"items\", []):\n",
        "            video_id = item[\"id\"][\"videoId\"]\n",
        "\n",
        "            # Lấy chi tiết video\n",
        "            video_response = youtube.videos().list(\n",
        "                part=\"snippet,statistics\",\n",
        "                id=video_id\n",
        "            ).execute()\n",
        "\n",
        "            for video in video_response.get(\"items\", []):\n",
        "                snippet = video[\"snippet\"]\n",
        "                stats = video.get(\"statistics\", {})\n",
        "\n",
        "                videos.append({\n",
        "                    \"title\": snippet[\"title\"],\n",
        "                    \"views\": stats.get(\"viewCount\", 0),\n",
        "                    \"likes\": stats.get(\"likeCount\", 0),\n",
        "                    \"comments\": stats.get(\"commentCount\", 0),\n",
        "                    \"publishedAt\": snippet[\"publishedAt\"].split(\"T\")[0],  # chỉ lấy YYYY-MM-DD\n",
        "                    \"tags\": \", \".join(snippet.get(\"tags\", [])) if \"tags\" in snippet else \"\",\n",
        "                    \"channelTitle\": snippet.get(\"channelTitle\", \"\")\n",
        "                })\n",
        "\n",
        "        # Nếu có trang tiếp theo thì crawl tiếp\n",
        "        next_page_token = search_response.get(\"nextPageToken\")\n",
        "        if not next_page_token:\n",
        "            break  # hết dữ liệu\n",
        "\n",
        "    return videos[:max_videos]\n",
        "\n",
        "# ====== 3. Crawl dữ liệu ======\n",
        "query = \"tivi\"\n",
        "results = youtube_search_scroll(query, max_videos=500)\n",
        "\n",
        "# ====== 4. Xuất CSV ======\n",
        "df = pd.DataFrame(results)\n",
        "df.to_csv(\"/content/drive/MyDrive/Youtube_crawled_data/TIVI_videos.csv\", index=False, encoding=\"utf-8-sig\")\n",
        "\n",
        "print(\"✅ Đã lưu thành công vào TIVI_videos.csv\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nhIIzaNfKAPh",
        "outputId": "5b429b4f-4a80-4e57-e641-2b7f35115cbe"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "✅ Đã lưu thành công vào TIVI_videos.csv\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "LÒ NƯỚNG"
      ],
      "metadata": {
        "id": "sZqkazxwKGXf"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from googleapiclient.discovery import build\n",
        "import pandas as pd\n",
        "\n",
        "# ====== 1. Cấu hình API ======\n",
        "API_KEY = \"AIzaSyAS5BoEfqdEIMxRrXO1MfA8WHYrFwrSHhE\"\n",
        "YOUTUBE_API_SERVICE_NAME = \"youtube\"\n",
        "YOUTUBE_API_VERSION = \"v3\"\n",
        "\n",
        "youtube = build(YOUTUBE_API_SERVICE_NAME, YOUTUBE_API_VERSION, developerKey=API_KEY)\n",
        "\n",
        "# ====== 2. Hàm crawl video ======\n",
        "def youtube_search_scroll(query, max_videos=100):\n",
        "    videos = []\n",
        "    next_page_token = None\n",
        "\n",
        "    while len(videos) < max_videos:\n",
        "        search_response = youtube.search().list(\n",
        "            q=query,\n",
        "            part=\"id,snippet\",\n",
        "            type=\"video\",\n",
        "            maxResults=50,\n",
        "            pageToken=next_page_token\n",
        "        ).execute()\n",
        "\n",
        "        for item in search_response.get(\"items\", []):\n",
        "            video_id = item[\"id\"][\"videoId\"]\n",
        "\n",
        "            # Lấy chi tiết video\n",
        "            video_response = youtube.videos().list(\n",
        "                part=\"snippet,statistics\",\n",
        "                id=video_id\n",
        "            ).execute()\n",
        "\n",
        "            for video in video_response.get(\"items\", []):\n",
        "                snippet = video[\"snippet\"]\n",
        "                stats = video.get(\"statistics\", {})\n",
        "\n",
        "                videos.append({\n",
        "                    \"title\": snippet[\"title\"],\n",
        "                    \"views\": stats.get(\"viewCount\", 0),\n",
        "                    \"likes\": stats.get(\"likeCount\", 0),\n",
        "                    \"comments\": stats.get(\"commentCount\", 0),\n",
        "                    \"publishedAt\": snippet[\"publishedAt\"].split(\"T\")[0],  # chỉ lấy YYYY-MM-DD\n",
        "                    \"tags\": \", \".join(snippet.get(\"tags\", [])) if \"tags\" in snippet else \"\",\n",
        "                    \"channelTitle\": snippet.get(\"channelTitle\", \"\")\n",
        "                })\n",
        "\n",
        "        # Nếu có trang tiếp theo thì crawl tiếp\n",
        "        next_page_token = search_response.get(\"nextPageToken\")\n",
        "        if not next_page_token:\n",
        "            break  # hết dữ liệu\n",
        "\n",
        "    return videos[:max_videos]\n",
        "\n",
        "# ====== 3. Crawl dữ liệu ======\n",
        "query = \"lò nướng\"\n",
        "results = youtube_search_scroll(query, max_videos=500)\n",
        "\n",
        "# ====== 4. Xuất CSV ======\n",
        "df = pd.DataFrame(results)\n",
        "df.to_csv(\"/content/drive/MyDrive/Youtube_crawled_data/LONUONG_videos.csv\", index=False, encoding=\"utf-8-sig\")\n",
        "\n",
        "print(\"✅ Đã lưu thành công vào LONUONG_videos.csv\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "miyVaWEHLEOS",
        "outputId": "91e8d35c-4664-4aca-ba70-9903232d5ce5"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "✅ Đã lưu thành công vào LONUONG_videos.csv\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "BÀN ỦI"
      ],
      "metadata": {
        "id": "q8qALhYwjCIA"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from googleapiclient.discovery import build\n",
        "import pandas as pd\n",
        "\n",
        "# ====== 1. Cấu hình API ======\n",
        "API_KEY = \"AIzaSyAS5BoEfqdEIMxRrXO1MfA8WHYrFwrSHhE\"\n",
        "YOUTUBE_API_SERVICE_NAME = \"youtube\"\n",
        "YOUTUBE_API_VERSION = \"v3\"\n",
        "\n",
        "youtube = build(YOUTUBE_API_SERVICE_NAME, YOUTUBE_API_VERSION, developerKey=API_KEY)\n",
        "\n",
        "# ====== 2. Hàm crawl video ======\n",
        "def youtube_search_scroll(query, max_videos=100):\n",
        "    videos = []\n",
        "    next_page_token = None\n",
        "\n",
        "    while len(videos) < max_videos:\n",
        "        search_response = youtube.search().list(\n",
        "            q=query,\n",
        "            part=\"id,snippet\",\n",
        "            type=\"video\",\n",
        "            maxResults=50,\n",
        "            pageToken=next_page_token\n",
        "        ).execute()\n",
        "\n",
        "        for item in search_response.get(\"items\", []):\n",
        "            video_id = item[\"id\"][\"videoId\"]\n",
        "\n",
        "            # Lấy chi tiết video\n",
        "            video_response = youtube.videos().list(\n",
        "                part=\"snippet,statistics\",\n",
        "                id=video_id\n",
        "            ).execute()\n",
        "\n",
        "            for video in video_response.get(\"items\", []):\n",
        "                snippet = video[\"snippet\"]\n",
        "                stats = video.get(\"statistics\", {})\n",
        "\n",
        "                videos.append({\n",
        "                    \"title\": snippet[\"title\"],\n",
        "                    \"views\": stats.get(\"viewCount\", 0),\n",
        "                    \"likes\": stats.get(\"likeCount\", 0),\n",
        "                    \"comments\": stats.get(\"commentCount\", 0),\n",
        "                    \"publishedAt\": snippet[\"publishedAt\"].split(\"T\")[0],  # chỉ lấy YYYY-MM-DD\n",
        "                    \"tags\": \", \".join(snippet.get(\"tags\", [])) if \"tags\" in snippet else \"\",\n",
        "                    \"channelTitle\": snippet.get(\"channelTitle\", \"\")\n",
        "                })\n",
        "\n",
        "        # Nếu có trang tiếp theo thì crawl tiếp\n",
        "        next_page_token = search_response.get(\"nextPageToken\")\n",
        "        if not next_page_token:\n",
        "            break  # hết dữ liệu\n",
        "\n",
        "    return videos[:max_videos]\n",
        "\n",
        "# ====== 3. Crawl dữ liệu ======\n",
        "query = \"bàn ủi\"\n",
        "results = youtube_search_scroll(query, max_videos=500)\n",
        "\n",
        "# ====== 4. Xuất CSV ======\n",
        "df = pd.DataFrame(results)\n",
        "df.to_csv(\"/content/drive/MyDrive/Youtube_crawled_data/BANUI_videos.csv\", index=False, encoding=\"utf-8-sig\")\n",
        "\n",
        "print(\"✅ Đã lưu thành công vào BANUI_videos.csv\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ivf5xZ5QjDJG",
        "outputId": "9847073a-c802-453d-ba14-1619bf17bc3e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "✅ Đã lưu thành công vào BANUI_videos.csv\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "BẾP"
      ],
      "metadata": {
        "id": "TgglXg_Nj0LT"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from googleapiclient.discovery import build\n",
        "import pandas as pd\n",
        "\n",
        "# ====== 1. Cấu hình API ======\n",
        "API_KEY = \"AIzaSyAS5BoEfqdEIMxRrXO1MfA8WHYrFwrSHhE\"\n",
        "YOUTUBE_API_SERVICE_NAME = \"youtube\"\n",
        "YOUTUBE_API_VERSION = \"v3\"\n",
        "\n",
        "youtube = build(YOUTUBE_API_SERVICE_NAME, YOUTUBE_API_VERSION, developerKey=API_KEY)\n",
        "\n",
        "# ====== 2. Hàm crawl video ======\n",
        "def youtube_search_scroll(query, max_videos=100):\n",
        "    videos = []\n",
        "    next_page_token = None\n",
        "\n",
        "    while len(videos) < max_videos:\n",
        "        search_response = youtube.search().list(\n",
        "            q=query,\n",
        "            part=\"id,snippet\",\n",
        "            type=\"video\",\n",
        "            maxResults=50,\n",
        "            pageToken=next_page_token\n",
        "        ).execute()\n",
        "\n",
        "        for item in search_response.get(\"items\", []):\n",
        "            video_id = item[\"id\"][\"videoId\"]\n",
        "\n",
        "            # Lấy chi tiết video\n",
        "            video_response = youtube.videos().list(\n",
        "                part=\"snippet,statistics\",\n",
        "                id=video_id\n",
        "            ).execute()\n",
        "\n",
        "            for video in video_response.get(\"items\", []):\n",
        "                snippet = video[\"snippet\"]\n",
        "                stats = video.get(\"statistics\", {})\n",
        "\n",
        "                videos.append({\n",
        "                    \"title\": snippet[\"title\"],\n",
        "                    \"views\": stats.get(\"viewCount\", 0),\n",
        "                    \"likes\": stats.get(\"likeCount\", 0),\n",
        "                    \"comments\": stats.get(\"commentCount\", 0),\n",
        "                    \"publishedAt\": snippet[\"publishedAt\"].split(\"T\")[0],  # chỉ lấy YYYY-MM-DD\n",
        "                    \"tags\": \", \".join(snippet.get(\"tags\", [])) if \"tags\" in snippet else \"\",\n",
        "                    \"channelTitle\": snippet.get(\"channelTitle\", \"\")\n",
        "                })\n",
        "\n",
        "        # Nếu có trang tiếp theo thì crawl tiếp\n",
        "        next_page_token = search_response.get(\"nextPageToken\")\n",
        "        if not next_page_token:\n",
        "            break  # hết dữ liệu\n",
        "\n",
        "    return videos[:max_videos]\n",
        "\n",
        "# ====== 3. Crawl dữ liệu ======\n",
        "query = \"bếp\"\n",
        "results = youtube_search_scroll(query, max_videos=500)\n",
        "\n",
        "# ====== 4. Xuất CSV ======\n",
        "df = pd.DataFrame(results)\n",
        "df.to_csv(\"/content/drive/MyDrive/Youtube_crawled_data/BEP_videos.csv\", index=False, encoding=\"utf-8-sig\")\n",
        "\n",
        "print(\"✅ Đã lưu thành công vào BEP_videos.csv\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RokuwyaKj1Kj",
        "outputId": "3a0c6446-4a08-4d2f-ba51-0decb9f7e25c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "✅ Đã lưu thành công vào BEP_videos.csv\n"
          ]
        }
      ]
    }
  ]
}